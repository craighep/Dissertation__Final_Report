\chapter{Evaluation}
Upon completion of the application, it is now necessary to evaluate both the application and project as a whole. This section will address a number of topics, in order to grasp an overall effectiveness of the project. For the purposes of highlighting points such as how well requirements were set out, or how well the application fulfilled its purpose, this evaluation has been broken down into the principle stages of the project. At the end, a small self-evaluation will describe what the author of this paper and application has felt was learned through this project in terms of personal and technical achievements.

\section{Anlaysis and design decisions}
Firstly, answering the question of how successful gathering requirements, the process of this started with looking at the initial project choice and language choice. After giving a brief overview of what the purpose and reasoning for this project, the language choice was an easy decision because WebGL could only run under the JavaScript language. Identifying this, analysing what technologies to use was then found to be much easier. 

The amount of research into the background topics was to a good amount that lead up to the discovery of the 15 degree increments idea (though later revised to 45 for interpolation issues), and meetings ensured that a sensible list of feature sets were created. By preparing questions in the initial project specification, having meetings clarified some of the technology choices, and discovered in more detail functions required of the application. In addition to the research shown in the primary report, the appendix added a even greater level of detail into the research of OLAN, and the expect Aresti figures to be generated.

Looking at the methodology choice in more detail, the reasoning for create a hybrid of the waterfall and feature driven was backed up for personal views towards the two processes, and technical efficiency reasons. By outlining the process in as much detail as possible ensured that the project allowed the design, implementation and testing phases to follow a strict plan. In order to support the methodology choice, both project and implementation Gantt charts helped to show where the project would be divided in terms of project time. Where this assignment was more heavily weighted towards implementation and testing, this was taken into account when assigning amounts of project time.

Diagrams helped tremendously in designing the project including the model view controller pattern mock-up, which provided the design for how the application would interact with the front and back end. Using the MVC diagram, it was possible to see what kind of general modules or classes would be required to run the application and communicate with the canvas. The MVC pattern also paved the way to introduce the idea of using a whole set of different design patterns, such as the observer pattern, which like MVC provided a way of connecting with front-end elements whilst keeping the model unaware of the them. A lot of research into various design patterns possible for JavaScript was taken into account, with reasoning given for choosing to use or not to use different patterns.

Researching into some of the technologies before beginning implementation also helped a great deal later on in the project, as it reduced set up time for items like RequireJS. By browsing example applications and work on-line also using Three.js, it gave a wider more general idea on what the most efficient way of creating a Three.js application, and what practices to follow. This was the same for the plain JavaScript code, where items such as local storage were researched and samples viewed before thinking how this application could implement them.

\section{Application and testing evaluation}
The second section of the project evaluation concerns how well the methodology was put to use, and overall, how successful the completed application was at fulfilling requirements. As FDD would be the principle means of implementation, an iteration approach to creating each feature set was used. At the start of the section, the iteration method was outlined, to ensure that each iteration followed the same procedures and testing methods. By doing this, it made sure that the time given to each task was fair and gave as best possible to finish as many features as possible.

As it can be seen in the section itself, not all features were completed initially, with some issues and features remaining missing even at the end of the time given to implementation. Features such as the movie-reel, where it was initially planned that the same part of code logic used to construct manoeuvres would be used to construct mini Aresti figures at the bottom of the page. During some investigation into how it could be achieved though, it was thought it would be firstly too consuming on the speed of the application, and too consuming in terms of development time. Therefore, a compromise was made, and simple images were loaded onto the movie-reel.

Issues with the manoeuvres that were drawn on the canvas led to some delays in the project, and a decision was taken to move to the next feature implementation meant that some of the features that may have not been done at all if the problem causing task was continued with. Although in FDD practice each feature should be done one at a time, moving on when the previous is complete, by going back to the problem later on but making sure there would be enough time to fix the issue was remaining, gave a better chance of a more complete application.

As mentioned in the implementation stage of this report, although the issue was not fixed at the time of that specific stage, the issue with rotations causing the drawing problem was continually worked on. At the latter stage of this report and following a meeting with the project supervisor, it was decided it would be better to ensure a full report is ready and append any fixes documented extra to the actual printed and binded report. Due to this, the changes after the print date were appended to the end of this report in appendix E. 

There were three primary means of testing during this stage of the project, each of which were chosen were it was felt appropriate. For instance, creating JSUnit tests where the feature was heavily animation based would be sufficient to test the entire feature, so usability tests solved that problem. It was ensured that each feature set had its own tests created, whether it be usability or JSUnit. Because of the use of the Jasmine framework, and linking this up to Travis, it was possible to see if any tests were failing due to refactoring or fixes. By getting alerts on a build failure, it meant the speed in which bug fixing could occur was faster.

The user questionnaire helped to evaluate the completed application and define how well the application met its needs. By creating a questionnaire where only two options were possible, meant that users would be more inclined to reply to the questionnaire quicker. This was true when all handed out were returned the next day, allowing reviewing and charts to be created from the answers. Using Google forms also provided a nice return style of data, allowing easy charts to be made and assumptions created. One key suggestion that appeared from the questionnaires involved the loading time of the application, where the model aircraft seemed too slow.

The parts of the completed application that should be highlighted as meeting or not meeting major requirements:
\begin{itemize}
	\item OLAN to 3D manoeuvres- These caused problamtic, and were debugged thouroughly, but due to time constraints, were not fixed within the projet time, unless mentioned within appendix E. Parameters for individual OLAN was not possible though moving the start position was.
	\item The ability to animate the flight- Manoeuvres were linkable, and could be animated along with the aircraft model. The ability to pause and change speed was also an added feature.
	\item A scene with cameras, lighting and various options- All of these were implemented, with added features such as on-board view for flights.
	\item Added features such as the movie-reel- Although only pictures, this feature proved useful to users, and gave a live update to the the progress of animation.
	\item Control sticks- Not implemented due to time constraints.
	\item Saving and loading of flights- Both JSON and local storage implemented as planned, and ahead of time.
	\item A suitable GUI- Both a mobile and desktop responsive site created.
	\item Documentation and testing- JSDoc for code, and this report for explaining the project, and the application was tested successfully and thoroughly.
\end{itemize}

The GUI should be particularly mentioned here also, with it being very user orientated. This was a feature that was felt it had been quite professionally made and a good level of detail added. Items like pop-ups were made not be annoying, and loading bars were added to allow users to always know when and what the status of events were while running certain operations. Menus were also usefully made to be hidden to allow for maximum workspace on the canvas.

\section{Project improvements}
Now that the walk-through of the project has been completed, each detailed with issues highlighted, there are some possible improvements that could have been made to the way the project was done if it was started again knowing what happened the first time.

A feature improvement that would have been useful to be added, but due to time constraints did not happen, was an extension of the warnings when entering OLAN, which was to check for none-compatible OLAN. For example, an OLAN move which exited facing upside down followed by another upwards orientated manouevre should not be allowed. 

The first project improvement would be to research more into both how to construct shapes in Three.js, so that issues that were found when creating manoeuvres could have been avoided. An alternative approach could have also been to change libraries all together. By looking for similar libraries to Three.js, a library may be present that could have made the task much easier or simpler. 

It could have also been that the size of the feature sets during implementation were too large, and could have been broken down more. By having smaller feature sets, then the application would have suffered less if one fell behind schedule. This would be because project time would have been divided more fairly, and would have been easier to track.

This leads onto the idea of better time tracking tools used. If there were some form of issue tracker used, then each feature during implementation could have a detailed task representation, including issues created where they may have occurred. A bug tracker such as Jira could have proved very useful, and would have also automatically have been able to generate informative graphs and statistics on implementation for use in progress checking.

The use of appendix is something that could be considered in a future project of this kind, where it could have been taken advantage of much more. Items such as testing could be expanded more for usability testing, where screen shots or more supporting diagrams could be shown. It is important to make sure that there are as much supporting facts and figures as required when explaining why something was tested in such a way.

\section{Future work}
Personally, I will be continuing on with this project after the assessment of this module is complete. I would like to expand the simulator to allow for the remote controller to be shown where joysticks would be pushed for each manoeuvre, alongside adding better compatibility for tablet devices. Issues like the drawing of OLAN shapes will also be high on the list for changes I will be performing if they still remain issues after the hand-in. On a project which I enjoyed so much, this is something I want to continue adding to for the foreseeable future, hopefully introducing to Internet community for suggestions or changes directly from others.

\section{Self-Evaluation}
For this final section of the report, I the author can now evaluate my own personal experiences whilst creating the application. I will explain what skills were developed through my time during the project, and what if any I struggled to get working or working in a desired way.

The way I used a wide range of different supporting applications in order to design, create and test the application I think was more than sufficient for a project of this size. The use of a build sever like Travis helped lots due to its on-commit build function. Each time I received any email stating a build had failed meant I was able to act quickly fixing an issue before continuing on with current development.

There were a lot of applications I had not been involved with before too, such as Jasmine. I showed the willingness to try unknown frameworks such as these in order to make a more professional project. I the analysis section of the project I showed how I made sure to research and try out some of the technologies like Three.js before using them for my application.

The way I handled problems during implementation meant I could not let the rest of the application suffer from issues with certain features such as generating the manoeuvre shapes. However, I did have to decide at the time how much project time I should have used before moving on. In all, I believe I handled the pressure well, and ensured that even though the feature was complete, it did not push back the rest of the project. I then set myself personal aims to complete each feature ahead of time in order to create time to fix previous problems.

One rather large issue which I will learn from for any project I do in the future is to ensure binding and printing are taken away from project time from the beginning, to make sure absolute deadlines are earlier to allow for the report to contain everything that is required. By having the issue I had generating OLAN shapes tested me on how to tackle an issue that that the report relied on, causing me to ask advice from my supervisor on whether to stop development as soon as the report is printed, or whether to carry on with code even though the report would not reflect it. By printing a separate document, later, this was a clever way of getting round such an issue.

Overall, I have learned a great deal of time management skills during this project, and due to this being the first time I have put FDD to practice, it has given me the chance to explore new means of creating an application and seeing how effective performing all the stages is different orders can effect how project time is divided up. Since this report was written in-line with the project, I found it very easy to pick out important and relevant topics for each section, as they were 'fresh on the mind'.

I have put to use many practices I have picked up from modules at my time in university, from choosing methodologies, to choosing the license type for my application. Choosing WebGL and Javascript as the primary languages for this project was also heavily endorsed by my experiences with a range of languages throughout my previous years at university, and I simply wanted to work with a language I would enjoy working with the most.

Using a work blog helped tremendously throughout this project, as it allowed me to keep track of what work had been done when, and gave me accurate dates on which I had completed parts of the project. I plan to use blog as tracking mechanisms for any future projects.

If I were to perform a project like this again though, I may stick to a more strict waterfall methodology method of working, to ensure that work that needs to be done is concentrated on more and given more flexibility on time. I would have also been happier testing the entire application after development, as this could have meant time could have been spent more on developing rather than forcing myself to break away every so often and test.

\clearpage

\section{Word count}
It was important to keep the word count of the document under the project requirements limit. I found this to be manageable by keeping track of each section's word count throughout the time writing this report. The count of this report can be seen in~\ref{tbl:count}.

\begin{table}[h!]
	\caption{Word count calculated using Tex-count~\cite{count} Perl script.}
	\begin{tabular}{|l|l|}
		\hline
		\textbf{Count} & \textbf{Value}                                                                \\ \hline
		Body of document, not including figure captions, table captions, or table contents.   &  20,105\\ \hline
	\end{tabular}
	\label{tbl:count}
\end{table}

\section{Licensing the application}

As found in Appendix B, all the libraries used in this project were created with the MIT license allowing me to also license my application under this. The reasoning for this is because I plan on both continuing work on the application, and allowing others to do the same, or even branching off and creating their own take on the application. I believe in freely spreading code and functionality, and if my application can help any one else in any needs they may have, the MIT license allows this. The full license can be found in the 'LICENSE' file in the source code folder or in appendix B section 2.