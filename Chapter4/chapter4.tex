\chapter{Evaluation}
Upon completion of the application, it is now necessary to evaluate both the application and project as a whole. This section will address a number of topics, in order to grasp an overall effectiveness of the project. For the purposes of highlighting points such as how well requirements were set out, or how well the application fulfilled its purpose, this evaluation has been broken down into the principle stages of the project. At the end, a small self-evaluation will describe what the author of this paper and application has felt was learned through this project in terms of personal and technical achievements.

\section{Anlaysis and design decisions}
Firstly, answering the question of how successful gathering requirements, the process of this started with looking at the initial project choice and language choice. After giving a brief overview of what the purpose and reasoning for this project, the language choice was an easy decision because WebGL could only run under the JavaScript language. Identifying this, analysing what technologies to use was then found to be much easier. 

The amount of research into the background topics was to a good amount that lead up to the discovery of the 15 degree increments idea (though later revised to 45 for interpolation issues), and meetings ensured that a sensible list of feature sets were created. By preparing questions in the initial project specification, having meetings clarified some of the technology choices, and discovered in more detail functions required of the application. In addition to the research shown in the primary report, the appendix added a even greater level of detail into the research of OLAN, and the expect Aresti figures to be generated.

The use of techniques such as the prioritised list of features from the scrum methodology helped in the implementation stage, by ensuring only important features were created first, so that the basic principles of the application were in place before any additional appearance or functional extras were added. Although the style of organising tasks this way is part of scrum, 

Looking at the methodology choice in more detail, the reasoning for create a hybrid of the waterfall and feature driven was backed up for personal views towards the two processes, and technical efficiency reasons. By outlining the process in as much detail as possible ensured that the project allowed the design, implementation and testing phases to follow a strict plan. In order to support the methodology choice, both project and implementation Gantt charts helped to show where the project would be divided in terms of project time. Where this assignment was more heavily weighted towards implementation and testing, this was taken into account when assigning amounts of project time.

Diagrams helped tremendously in designing the project, and in organising features. The first to be used was the use case diagram that was created to represent the features decided earlier, and to help categorise the features into feature sets. Feature sets were useful later on where wire-frames planned which options would be together. For instance, keeping the input of OLAN and the play/pause button together proved useful in the final application, and was placed so due to the planning using the use-case.

Other diagrams included the model view controller pattern mock-up, which provided the design for how the application would interact with the front and back end. Using the MVC diagram, it was possible to see what kind of general modules or classes would be required to run the application and communicate with the canvas. The MVC pattern also paved the way to introduce the idea of using a whole set of different design patterns, such as the observer pattern, which like MVC provided a way of connecting with front-end elements whilst keeping the model unaware of the them. A lot of research into various design patterns possible for JavaScript was taken into account, with reasoning given for choosing to use or not to use different patterns.

Because it had already been noted that JavaScript was a classless language, choosing to use modulation as a means of organising and simulating object-orientation was selected. Because modulation was similar to the way classes worked, a class diagram felt most appropriate for displaying that aspect of the design. It was important to correctly identify which features should have had their own controllers and modules, because the coding was then be based heavily on the diagram.

Further research that helped structure of the requirements was the design of the GUI itself, planning firstly where features should display, and how each should interact in what order. Creating a GUI use case allowed for good detailed mock ups of the page, and identified where features were best suited. Again, this then made the implementation stage much easier and quicker to do when it came to placing features from the back end onto the GUI. A flow diagram also helped identify how the speed of various parts of the system might affect the time from opening the page to allowing users to input into the OLAN box. It was important to ensure that proper loading of the application would be complete before allowing use, as it would prevent users from crashing the application.

Researching into some of the technologies before beginning implementation also helped a great deal later on in the project, as it reduced set up time for items like RequireJS. By browsing example applications and work on-line also using Three.js, it gave a wider more general idea on what the most efficient way of creating a Three.js application, and what practices to follow. This was the same for the plain JavaScript code, where items such as local storage were researched and samples viewed before thinking how this application could implement them.

And to complete the analysis of the proposed application effectively, planning what technologies would be helpful to use during implementation was evaluated. By going to the smallest of detail, from selecting the version control to the IDE meant that when the project would move into the implementation stage, a clear path could be followed.

\section{Application and testing evaluation}
The second section of the project evaluation concerns how well the methodology was put to use, and overall, how successful the completed application was at fulfilling requirements. As FDD would be the principle means of implementation, an iteration approach to creating each feature set was used. At the start of the section, the iteration method was outlined, to ensure that each iteration followed the same procedures and testing methods. By doing this, it made sure that the time given to each task was fair and gave as best possible to finish as many features as possible.

As it can be seen in the section itself, not all features were completed initially, with some issues and features remaining missing even at the end of the time given to implementation. Features such as the movie-reel, where it was initially planned that the same part of code logic used to construct manoeuvres would be used to construct mini Aresti figures at the bottom of the page. During some investigation into how it could be achieved though, it was thought it would be firstly too consuming on the speed of the application, and too consuming in terms of development time. Therefore, a compromise was made, and simple images were loaded onto the movie-reel.

Issues with the manoeuvres that were drawn on the canvas led to some delays in the project, and a decision was taken to move to the next feature implementation meant that some of the features that may have not been done at all if the problem causing task was continued with. Although in FDD practice each feature should be done one at a time, moving on when the previous is complete, by going back to the problem later on but making sure there would be enough time to fix the issue was remaining, gave a better chance of a more complete application.

There were three primary means of testing during this stage of the project, each of which were chosen were it was felt appropriate. For instance, creating JSUnit tests where the feature was heavily animation based would be sufficient to test the entire feature, so usability tests solved that problem. It was ensured that each feature set had its own tests created, whether it be usability or JSUnit. Because of the use of the Jasmine framework, and linking this up to Travis, it was possible to see if any tests were failing due to refactoring or fixes. By getting alerts on a build failure, it meant the speed in which bug fixing could occur was faster.

The user questionnaire helped to evaluate the completed application and define how well the application met its needs. By creating a questionnaire where only two options were possible, meant that users would be more inclined to reply to the questionnaire quicker. This was true when all handed out were returned the next day, allowing reviewing and charts to be created from the answers. Using Google forms also provided a nice return style of data, allowing easy charts to be made and assumptions created. One key suggestion that appeared from the questionnaires involved the loading time of the application, where the model aircraft seemed too slow.

The parts of the completed application that should be highlighted as meeting or not meeting major requirements:
\begin{itemize}
	\item OLAN to 3D manoeuvres- At first problematic, but after testing and fixes, the main functionality here was complete (parameters for individual OLAN was not possible though).
	\item The ability to animate the flight- Manoeuvres were linkable, and could be animated along with the aircraft model. The ability to pause and change speed was also an added feature.
	\item A scene with cameras, lighting and various options- All of these were implemented, with added features such as on-board view for flights.
	\item Added features such as the movie-reel- Although only pictures, this feature proved useful to users, and gave a live update to the the progress of animation.
	\item Control sticks- Not implemented due to time constraints.
	\item Saving and loading of flights- Both JSON and local storage implemented as planned, and ahead of time.
	\item A suitable GUI- Both a mobile and desktop responsive site created.
	\item Documentation and testing- JSDoc for code, and this report for explaining the project, and the application was tested successfully and thoroughly.
\end{itemize}

\section{Project improvements}
Now that the walk-through of the project has been completed, each detailed with issues highlighted, there are some possible improvements that could have been made to the way the project was done if it was started again knowing what happened the first time.

The first would be to research more into both how to construct shapes in Three.js, so that issues that were found when creating manoeuvres could have been avoided. An alternative approach could have also been to change libraries all together. By looking for similar libraries to Three.js, a library may be present that could have made the task much easier or simpler. 

It could have also been that the size of the feature sets during implementation were too large, and could have been broken down more. By having smaller feature sets, then the application would have suffered less if one fell behind schedule. This would be because project time would have been divided more fairly, and would have been easier to track.

This leads onto the idea of better time tracking tools used. If there were some form of issue tracker used, then each feature during implementation could have a detailed task representation, including issues created where they may have occurred. A bug tracker such as Jira could have proved very useful, and would have also automatically have been able to generate informative graphs and statistics on implementation for use in progress checking.

The use of appendix is something that could be considered in a future project of this kind, where it could have been taken advantage of much more. Items such as testing could be expanded more for usability testing, where screen shots or more supporting diagrams could be shown. It is important to make sure that there are as much supporting facts and figures as required when explaining why something was tested in such a way.

\section{Self-Evaluation}
For this final section of the report, I the author can now evaluate my own personal experiences whilst creating the application. I will explain what skills were developed through my time during the project, and what if any I struggled to get working or working in a desired way.

The way I used a wide range of different supporting applications in order to design, create and test the application I think was more than sufficient for a project of this size. The use of a build sever like Travis helped lots due to its on-commit build function. Each time I received any email stating a build had failed meant I was able to act quickly fixing an issue before continuing on with current development.

There were a lot of applications I had not been involved with before too, such as Jasmine. I showed the willingness to try unknown frameworks such as these in order to make a more professional project. I the analysis section of the project I showed how I made sure to research and try out some of the technologies like Three.js before using them for my application.

The way I handled problems during implementation meant I could not let the rest of the application suffer from issues with certain features such as generating the manoeuvre shapes. However, I did have to decide at the time how much project time I should have used before moving on. In all, I believe I handled the pressure well, and ensured that even though the feature was complete, it did not push back the rest of the project. I then set myself personal aims to complete each feature ahead of time in order to create time to fix previous problems.

Overall, I have learned a great deal of time management skills during this project, and due to this being the first time I have put FDD to practice, it has given me the chance to explore new means of creating an application and seeing how effective performing all the stages is different orders can effect how project time is divided up. Since this report was written in-line with the project, I found it very easy to pick out important and relevant topics for each section, as they were 'fresh on the mind'.
